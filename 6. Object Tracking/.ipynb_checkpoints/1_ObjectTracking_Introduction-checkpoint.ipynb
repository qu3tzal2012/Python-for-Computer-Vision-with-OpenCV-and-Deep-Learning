{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/worklifesg/Python-for-Computer-Vision-with-OpenCV-and-Deep-Learning/blob/main/6.%20Object%20Tracking/1_ObjectTracking_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ3fGAmciSyq"
   },
   "source": [
    "### Object Tracking\n",
    "\n",
    "In this section, we will cover:\n",
    "\n",
    "- Basic Object Tracking Techniques\n",
    " - Optical Flow\n",
    " - Meanshift and Camshift\n",
    "- Advanced Tracking\n",
    " - Built-In Tracking APIs\n",
    "\n",
    "#### Optical Flow\n",
    "\n",
    "- It is defined ss the pattern of apparent motion of image objects between 2 consecutive frames caused by the movement of object or camera.\n",
    "- <b> Assumptions: </b>\n",
    " - Pixel intensities of object between consecutive frames <b> DONOT CHANGWE </b>\n",
    " - Neighbouring pixels have similar motion\n",
    "- Methods:\n",
    " - Take given set of points and a frame.\n",
    " - Attempt to find those points in next frame.\n",
    " - Upto user to supply the points to track.\n",
    "- We need to also see that in which direction object is moving or is it the camera which is moving.\n",
    "-<b> General way to track a object: </b> We will pass <b> previous frame, previous points and current points </b> to the <b> Lucas Kanade </b> function.\n",
    "- The function then attempts to locate points in the current frame.\n",
    "- <b> Lucas Kanade </b> computes optical flow for a <b> sparse </b> feature set i.e. only points that it was told to track.\n",
    " - But to track all points in the video, we have to use <b> Gunner Farneback's algorithm that computes dense optical flow </b>. It will color them black if no flow is detected.\n",
    "\n",
    "- <b> Optical Flow Equation:</b>\n",
    " - Consider an object with intensity $I (x, y, t)$, after time $dt$, it moves to by $dx$ and $dy$, now, the new intensity would be, $I (x+dx, y+dy, t+dt)$.\n",
    " - We, assume that the pixel intensities are constant between the two frames, i.e.,\n",
    "\\begin{align*}\n",
    " I (x, y, t) = I (x+dx, y+dy, t+dt)\n",
    "\\end{align*}\n",
    "\n",
    " - Then take taylor series approximation of right-hand side, resulting in,\n",
    "\n",
    " \\begin{align*}\n",
    " \\dfrac{dI}{dx}\\delta x+\\dfrac{dI}{dy}\\delta y+\\dfrac{dI}{dt}\\delta t=0\n",
    " \\end{align*}\n",
    "\n",
    " - Dividing equation above by $\\delta t $ gives us <b> Optical Flow Equation:</b>\n",
    "\n",
    " \\begin{align*}\n",
    " \\dfrac{dI}{dx}u+\\dfrac{dI}{dy}v+\\dfrac{dI}{dt}=0\n",
    " \\end{align*}\n",
    "\n",
    " - where $u= \\delta x/\\delta t, v= \\delta y/\\delta t$ and $dl/dx$ is image gradient along horizontal axis and $dl/dy$ is image gradient along vertical axis and $dl/dt$ is along the time. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Lucas - Kanade Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rwE1t2flOcWC"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5pHIsw9HpKSe"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary to track corners\n",
    "corner_track_params = dict(maxCorners=10,\n",
    "                           qualityLevel=0.3,\n",
    "                           minDistance=7,\n",
    "                           blockSize=7)\n",
    "#parameters for Lucas Kanade function\n",
    "#Smaller window - more senstive to noise and may miss larger motions\n",
    "'''\n",
    "LK method using the idea of image pyramid \n",
    "Level0 - original image, Level1 - 1/2 resol, Level2 - 1/4 resol, Level3 - 1/8 resol, Level4 - 1/15 resol\n",
    "At each level the image is blurred and subsample i.e. allows to find optical flow at various resolutions\n",
    "'''\n",
    "lk_params = dict(winSize=(200,200),\n",
    "                 maxLevel=2,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agBAX3Jqrl-5"
   },
   "outputs": [],
   "source": [
    "# live streaming capturing of Sparse Optical Flow\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret,prev_frame = cap.read()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# points to track\n",
    "\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params)\n",
    "\n",
    "#mask\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "\n",
    "  ret, frame = cap.read()\n",
    "  frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts, None,**lk_params)\n",
    "\n",
    "  good_new = nextPts[status==1]\n",
    "  good_prev = prevPts[status==1]\n",
    "\n",
    "  for i, (new,prev), in enumerate(zip(good_new,good_prev)):\n",
    "    x_new,y_new = new.ravel()\n",
    "    x_prev,y_prev = prev.ravel()\n",
    "\n",
    "    mask = cv2.line(mask,(x_new,y_new),(x_prev,y_prev),(0,255,0),3)\n",
    "\n",
    "    frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1) #draing circle on current points in a frame are\n",
    "  \n",
    "  img = cv2.add(frame,mask)\n",
    "  cv2.imshow('tracking',img)\n",
    "\n",
    "  k = cv2.waitKey(30) & 0xFF\n",
    "  if k == 27:\n",
    "    break\n",
    "  \n",
    "  prev_gray = frame_gray.copy()\n",
    "  prevPts = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8vFes5mrlOmMsqhBSeUp2",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1_ObjectTracking_Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
